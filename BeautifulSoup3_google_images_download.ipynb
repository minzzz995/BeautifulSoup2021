{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1334815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google_images_download\n",
      "  Downloading google_images_download-2.8.0.tar.gz (14 kB)\n",
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium->google_images_download) (1.26.4)\n",
      "Building wheels for collected packages: google-images-download\n",
      "  Building wheel for google-images-download (setup.py): started\n",
      "  Building wheel for google-images-download (setup.py): finished with status 'done'\n",
      "  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14549 sha256=00aa30eaeb91fda81244776cf688b2e242be1da0c0393ca5675ebc194dc3c2ab\n",
      "  Stored in directory: c:\\users\\cpb06gamen\\appdata\\local\\pip\\cache\\wheels\\09\\09\\00\\7a4b1a816f726438cb51067db23c7f9efedf009b6a1bfa027a\n",
      "Successfully built google-images-download\n",
      "Installing collected packages: selenium, google-images-download\n",
      "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "! pip install google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a6d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c4ed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = Polar bears\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 20 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "\n",
      "Item no.: 2 --> Item name = baloons\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 20 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "\n",
      "Item no.: 3 --> Item name = Beaches\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 20 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "({'Polar bears': [], 'baloons': [], 'Beaches': []}, 0)\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download   #importing the library\n",
    "\n",
    "response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "\n",
    "arguments = {\"keywords\":\"Polar bears,baloons,Beaches\",\"limit\":20,\"print_urls\":True}   #creating list of arguments\n",
    "paths = response.download(arguments)   #passing the arguments to the function\n",
    "print(paths)   #printing absolute paths of the downloaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f58878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print('created '+directory)\n",
    "    except OSError:\n",
    "        print('Error : already Created' + directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a9fa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 Lying down position\n",
      "created data/Lying down position\n"
     ]
    }
   ],
   "source": [
    "search = input('검색 ')\n",
    "createFolder('data/'+search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c691e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.google.co.kr/search?q={quote_plus(search)}&safe=active&tbm=isch&ved=2ahUKEwjIzuqEjuzyAhVN4GEKHTPICzYQ2-cCegQIABAA&oq=Lying+down+position&gs_lcp=CgNpbWcQAzIECAAQEzIECAAQEzIECAAQEzIECAAQEzIECAAQEzIECAAQEzIECAAQEzIICAAQBRAeEBMyCAgAEAUQHhATMggIABAFEB4QE1Db0LQBWNvQtAFg_Na0AWgAcAB4AIAB6AGIAegBkgEDMi0xmAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&sclient=img&ei=1fU2YYiQBc3AhwOzkK-wAw&bih=937&biw=1920&hl=ko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "598f7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad1d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = soup.select('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbb52e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "imgurl = []\n",
    "\n",
    "for i in img:\n",
    "    try:\n",
    "        imgurl.append(i.attrs[\"src\"])\n",
    "    except KeyError:\n",
    "        imgurl.append(i.attrs[\"data-src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d132c588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading.........2\n",
      "downloading.........3\n",
      "downloading.........4\n",
      "downloading.........5\n",
      "downloading.........6\n",
      "downloading.........7\n",
      "downloading.........8\n",
      "downloading.........9\n",
      "downloading.........10\n",
      "downloading.........11\n",
      "downloading.........12\n",
      "downloading.........13\n",
      "downloading.........14\n",
      "downloading.........15\n",
      "downloading.........16\n",
      "downloading.........17\n",
      "downloading.........18\n",
      "downloading.........19\n",
      "downloading.........20\n",
      "downloading.........21\n",
      "downloading.........22\n",
      "downloading.........23\n",
      "downloading.........24\n",
      "downloading.........25\n",
      "downloading.........26\n",
      "downloading.........27\n",
      "downloading.........28\n",
      "downloading.........29\n",
      "downloading.........30\n",
      "downloading.........31\n",
      "downloading.........32\n",
      "downloading.........33\n",
      "downloading.........34\n",
      "downloading.........35\n",
      "downloading.........36\n",
      "downloading.........37\n",
      "downloading.........38\n",
      "downloading.........39\n",
      "downloading.........40\n",
      "downloading.........41\n",
      "downloading.........42\n",
      "downloading.........43\n",
      "downloading.........44\n",
      "downloading.........45\n",
      "downloading.........46\n",
      "downloading.........47\n",
      "downloading.........48\n",
      "downloading.........49\n",
      "downloading.........50\n",
      "downloading.........51\n",
      "downloading.........52\n",
      "downloading.........53\n",
      "downloading.........54\n",
      "downloading.........55\n",
      "downloading.........56\n",
      "downloading.........57\n",
      "downloading.........58\n",
      "downloading.........59\n",
      "downloading.........60\n",
      "downloading.........61\n",
      "downloading.........62\n"
     ]
    }
   ],
   "source": [
    "for i in imgurl:\n",
    "    urlretrieve(i, \"data/\"+ search +'/' + search + str(n) + \".jpg\")\n",
    "    n += 1\n",
    "    print('downloading.........{}'.format(n))\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149f65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7125b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
